{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03cbe21-ea60-4ab4-956e-ed60fb754ce9",
   "metadata": {},
   "source": [
    "### Check whether gpu available or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d40177-70a5-45b0-900a-705acc8cdcae",
   "metadata": {},
   "source": [
    "#### For Nvidia system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ff5a2-561e-4ab5-8f26-7e55025eea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0aa29-52ff-4d94-9540-47185178b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available for Apple Silicon\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU is available for acceleration.')\n",
    "    device = torch.device(\"cuda\")  # Use MPS backend\n",
    "else:\n",
    "    print('GPU is not available. Using CPU.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Selected device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138b53b-ff3e-4265-866f-0f346a4a5272",
   "metadata": {},
   "source": [
    "#### For Apple Silicon system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c72b04-0b86-476b-a58c-3764263413b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available for Apple Silicon\n",
    "if torch.backends.mps.is_available():\n",
    "    print('Metal is available for acceleration.')\n",
    "    device = torch.device(\"mps\")  # Use MPS backend\n",
    "else:\n",
    "    print('Metal is not available. Using CPU.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Selected device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68904bd4-5023-49da-8f70-30b2d6f6fefe",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572f229-f7b9-4665-88c9-722911c4c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc56d50-b0a4-4fea-b383-0575f8c3fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk import pos_tag, word_tokenize, bigrams\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a254744-45ac-4a05-97e5-29700ed9e516",
   "metadata": {},
   "source": [
    "### Initialize Roberta and Other Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c0667-13b3-4a45-a8a5-98fd5d230a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Initialize CountVectorizer for n-gram feature extraction\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5c4d4-361f-4a11-884c-8f373278c2c0",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab3afa-38a9-4c08-9c05-7ae92d956f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"___Set the dataset path___\",\n",
    "              \"valid\": \"___Set the dataset path___\",\n",
    "              \"test\": \"___Set the dataset path___\"\n",
    "              }\n",
    "\n",
    "data = load_dataset('csv', data_files = data_files)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eacb4a-5bc5-4476-9e90-3b1045c07f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'].features\n",
    "data['test'][0]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords.words('english'))\n",
    "train_texts = [example['text'] for example in data['train']]\n",
    "vectorizer.fit(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9578d29-ab5d-4714-8687-0c440191a4f7",
   "metadata": {},
   "source": [
    "### Creating the data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68489c0-4356-40fe-aa87-acade1eac337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeReviewDataset(Dataset):\n",
    "    def __init__(self, dataset,vectorizer):\n",
    "        self.dataset = dataset\n",
    "        self.vectorizer = vectorizer\n",
    "        # CountVectorizer(ngram_range=(1, 2), stop_words=stopwords.words('english'), dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def extract_linguistic_features(self, text):\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Generate POS tags\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        pos_tags_str = ['_'.join(tag) for tag in pos_tags]\n",
    "\n",
    "        # Generate bigrams\n",
    "        bigram_features = list(bigrams(tokens))\n",
    "        bigrams_str = ['_'.join(bigram) for bigram in bigram_features]\n",
    "\n",
    "        # Combine all features\n",
    "        all_features = ' '.join(pos_tags_str + bigrams_str)\n",
    "        return self.vectorizer.transform([all_features]).toarray()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset['text'][idx]\n",
    "        label = self.dataset['label'][idx]\n",
    "\n",
    "        # Tokenize text\n",
    "        encoded_input = tokenizer(text, truncation=True, max_length=128, padding='max_length', return_tensors='pt')\n",
    "        input_ids = encoded_input['input_ids'].squeeze()\n",
    "        attention_mask = encoded_input['attention_mask'].squeeze()\n",
    "\n",
    "        # Extract linguistic features\n",
    "        linguistic_features = self.extract_linguistic_features(text)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'linguistic_features': torch.tensor(linguistic_features, dtype=torch.float32).squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf29456-62aa-4e14-af3d-26ac0e81470f",
   "metadata": {},
   "source": [
    "### Creating Dataset Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961a4e9-a004-43fb-a7bd-5a301b65509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FakeReviewDataset(data['train'], vectorizer)\n",
    "test_dataset = FakeReviewDataset(data['test'], vectorizer)\n",
    "valid_dataset = FakeReviewDataset(data['valid'], vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a95c3-340e-4eb4-aabd-7b2a11ab3f07",
   "metadata": {},
   "source": [
    "### Padding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820437b-c341-4d84-8a5a-fec72d8b95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8fb3b-4526-4f5b-8a38-383a3e7c20a7",
   "metadata": {},
   "source": [
    "### Load the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09c863-152d-407c-83d7-d29111bc9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5868d3-df7c-4268-93e3-086bb457202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Compute the metrics\n",
    "    accuracy_result = accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision_result = precision.compute(predictions=predictions, references=labels, average=\"binary\")\n",
    "    recall_result = recall.compute(predictions=predictions, references=labels, average=\"binary\")\n",
    "    f1_result = f1.compute(predictions=predictions, references=labels, average=\"binary\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_result[\"accuracy\"],\n",
    "        \"precision\": precision_result[\"precision\"],\n",
    "        \"recall\": recall_result[\"recall\"],\n",
    "        \"f1\": f1_result[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a5ff3-d9f9-4fb6-a6ef-55e4df97878c",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e09efa-6843-4062-ac16-c871ed0938dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./model_output',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    fp16=False,  # Only set to True if your GPU supports FP16\n",
    "    load_best_model_at_end=True  # Useful for automatically picking the best model\n",
    ")\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa22621-69c9-4b23-85d5-30d2612df696",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c9ca1-33fd-41ac-8ffa-b640877c0d1b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22709877-69fd-49d9-a7d5-583d763216f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(test_dataset)\n",
    "for k, v in test_results.items():\n",
    "    print(k, \":\", v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
