{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6afbbf3-84bf-4603-8a83-fdcbf67103b8",
   "metadata": {},
   "source": [
    "### Check whether gpu available or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bcaf9-73cd-4718-86f8-c79f42187994",
   "metadata": {},
   "source": [
    "#### For Nvidia system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd81782-2b05-49bc-b359-490520927af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f7d54-23ef-4ef0-b989-2c454b90c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available for Apple Silicon\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU is available for acceleration.')\n",
    "    device = torch.device(\"cuda\")  # Use MPS backend\n",
    "else:\n",
    "    print('GPU is not available. Using CPU.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Selected device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fea8e-b83c-4929-8cf7-65bb58b05b19",
   "metadata": {},
   "source": [
    "#### For Apple Silicon system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d00945-f6dc-4995-929c-7c4409e1ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available for Apple Silicon\n",
    "if torch.backends.mps.is_available():\n",
    "    print('Metal is available for acceleration.')\n",
    "    device = torch.device(\"mps\")  # Use MPS backend\n",
    "else:\n",
    "    print('Metal is not available. Using CPU.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Selected device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ad3d3-b9a9-4cc4-8ba1-1f2fe38882e2",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecdc5a-783c-44ba-80be-f80b9dfe7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, AutoTokenizer, AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c749bc-df3a-4b0a-9a39-747424076dbf",
   "metadata": {},
   "source": [
    "### Configure \"Wndb\" login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebf85c-061e-47f6-bebf-ea4371d52c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"__project____\",\n",
    "    name=\"__name___\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"architecture\": \"DistilBERT\",\n",
    "    \"dataset\": \"full\",\n",
    "    \"epochs\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1873b-2376-4add-8dc7-85b87b3182f5",
   "metadata": {},
   "source": [
    "### Read the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fba85-0066-4682-a018-fe27d00ec9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Set your dataset path')\n",
    "validate_df = pd.read_csv('Set your dataset path')\n",
    "test_df = pd.read_csv('Set your dataset path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd97b10-1e11-460f-b867-1b6912fb98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = data.text\n",
    "        self.labels = data.label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.text[idx])\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1688e-9f7a-458e-9783-0114b829a154",
   "metadata": {},
   "source": [
    "### Generate tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146654b-8655-4c29-a462-c474a7181ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af6bc1-ad46-4aee-a4c3-38f118c6285c",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c73982-d364-41f9-a288-bc6f9309a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the capacity of your GPU, set...\n",
    "max_len = 256  # ... a suitable maximum length\n",
    "batch_size = 16  # ... a suitable batch size\n",
    "\n",
    "train_dataset = ReviewsDataset(train_df, tokenizer, max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validate_dataset = ReviewsDataset(validate_df, tokenizer, max_len)\n",
    "validate_loader = DataLoader(validate_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15e781-c31c-4932-aae9-4d011d6c2438",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4f48c-433e-44ee-be1e-7fc2a6d97c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a836bb6-5d98-4071-a335-9ac020abcafb",
   "metadata": {},
   "source": [
    "### Set the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2450fdf-2d8c-436e-9a83-eb9a0efc62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5) #Set the desired learning rate (lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2634ee-d97b-4cf8-b879-1167a081165b",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3351e-deb9-45ff-97f8-66806fec1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3  # Number of epochs\n",
    "total_start_time = time.time()\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_loss, batch_count = 0, 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch_start_time = time.time()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_end_time = time.time()\n",
    "        batch_duration = batch_end_time - batch_start_time\n",
    "        total_elapsed_time = batch_end_time - total_start_time\n",
    "        estimated_total_time = total_elapsed_time / (epoch * len(train_loader) + batch_count) * num_epochs * len(train_loader)\n",
    "        remaining_time = estimated_total_time - total_elapsed_time\n",
    "\n",
    "        # Calculate predictions from the model's logits\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update the count of correctly predicted labels\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        # Print loss and remaining time every 10 batches\n",
    "        if batch_count % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_count}, Loss: {loss.item():.4f}, \"\n",
    "                  f\"Time remaining: {remaining_time // 60:.0f}m {remaining_time % 60:.0f}s\")\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Reset counters for the next epoch\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    avg_loss = total_loss / batch_count if batch_count else 0\n",
    "    print(f\"End of Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Log training metrics to wandb\n",
    "    wandb.log({\"train_accuracy\": train_acc, \"train_loss\": avg_loss})\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(f\"Total training time: {(total_end_time - total_start_time)//60:.0f}m {(total_end_time - total_start_time)%60:.0f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da4833-6858-4b0d-9224-77f21af6b57f",
   "metadata": {},
   "source": [
    "### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b8950-43ff-441e-8e36-fec9d4a6228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_total_loss = 0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions, true_labels = [], []\n",
    "total_val_time = 0\n",
    "\n",
    "progress_bar = tqdm(validate_loader, desc=\"Validating\", leave=False)\n",
    "for batch in progress_bar:\n",
    "    val_start_time = time.time()\n",
    "\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Pass labels to the model to calculate loss\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        val_total_loss += loss.item()\n",
    "\n",
    "        # Convert logits to predictions\n",
    "        batch_predictions = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(batch_predictions.tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "        # Update correct and total counts for accuracy\n",
    "        val_correct += (batch_predictions == labels).sum().item()\n",
    "        val_total += labels.size(0)\n",
    "\n",
    "    val_end_time = time.time()\n",
    "    val_batch_time = val_end_time - val_start_time\n",
    "    total_val_time += val_batch_time\n",
    "\n",
    "    # Updating progress bar with elapsed and remaining time\n",
    "    avg_batch_time = total_val_time / (progress_bar.n + 1)\n",
    "    remaining_time = avg_batch_time * (len(validate_loader) - progress_bar.n - 1)\n",
    "    progress_bar.set_postfix(elapsed=f\"{total_val_time // 60:.0f}m {total_val_time % 60:.0f}s\", \n",
    "                             remaining=f\"{remaining_time // 60:.0f}m {remaining_time % 60:.0f}s\")\n",
    "\n",
    "# Calculate average validation loss and accuracy\n",
    "val_avg_loss = val_total_loss / len(validate_loader) if len(validate_loader) > 0 else 0\n",
    "val_acc = val_correct / val_total if val_total > 0 else 0\n",
    "\n",
    "# Log validation metrics to wandb\n",
    "wandb.log({\"val_accuracy\": val_acc, \"val_loss\": val_avg_loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3ce14-8580-4d20-ba1c-d86a4c009fc6",
   "metadata": {},
   "source": [
    "### Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6714eb4-900d-4730-8b2d-374ddca8f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f03a66-4c31-44bb-ae88-ad7425aa8287",
   "metadata": {},
   "source": [
    "### Reporting the result to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba0dc2-538c-42d1-9f19-9ad57b23424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_labels, predictions, output_dict=True)\n",
    "print(report)\n",
    "# Save as a serialized object\n",
    "with open('classification_report.pkl', 'wb') as file:\n",
    "    pickle.dump(report, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2bd87-0099-49d6-9e24-99e8f27a6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
